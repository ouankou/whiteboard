// Experimental test input for Accelerator directives
//  simplest scalar*vector operations
// Liao 1/15/2013
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <string.h>
#include <sys/timeb.h>
#include "axpy.h"

double read_timer_ms() {
    struct timeb tm;
    ftime(&tm);
    return (double) tm.time * 1000.0 + (double) tm.millitm;
}

/* change this to do saxpy or daxpy : single precision or double precision*/
#define REAL double
#define VEC_LEN 1024000 //use a fixed number for now
/* zero out the entire vector */
void zero(REAL *A, int n)
{
    int i;
    for (i = 0; i < n; i++) {
        A[i] = 0.0;
    }
}

/* initialize a vector with random floating point numbers */
void init(REAL *A, int n)
{
    int i;
    for (i = 0; i < n; i++) {
        A[i] = (double)drand48();
    }
}

/*serial version */
void axpy(REAL* x, REAL* y, long n, REAL a) {
  int i;
  for (i = 0; i < n; ++i)
  {
    y[i] += a * x[i];
  }
}

/* compare two arrays and return percentage of difference */
REAL check(REAL*A, REAL*B, int n)
{
    int i;
    REAL diffsum =0.0, sum = 0.0;
    for (i = 0; i < n; i++) {
        diffsum += fabs(A[i] - B[i]);
        sum += fabs(B[i]);
    }
    return diffsum/sum;
}

void axpy_ompacc(REAL* x, REAL* y, int n, REAL a);
void * entry_ptr = (void*)&axpy_ompacc; //key of the CUDA kernel function, could be anything
char cuda_entry_name[] = "axpy_cudakernel_1perThread";  //cuda kernel function name

#include <omptarget.h>
//the offloading entry is a map between <host_key, cuda_entry_name>
struct __tgt_offload_entry  axpy_ompacc_tgt_offload_entry = {(void*)&axpy_ompacc, cuda_entry_name, 0, 0, 0};
struct __tgt_offload_entry *__start_omp_offloading_entries = &axpy_ompacc_tgt_offload_entry;
struct __tgt_offload_entry *__stop_omp_offloading_entries = &__start_omp_offloading_entries[1];

/**
 * This function copy the cuda binary image into a char array, create data objects of
 * __tgt_device_image and __tgt_bin_desc that are used to register the cuda kernel 
 * info into the libomptarget runtime. In Clang/LLVM compiler, this code is automatically 
 * generated by the clang-offload-wrapper and the __tgt_register_lib call is put in the ctor
 *
 */
struct __tgt_bin_desc * cubin2chararray_register(char * binfilename) {

  //read cuda object file to char array
  FILE * file = fopen(binfilename, "r+");
  if (file == NULL) return NULL;
  fseek(file, 0, SEEK_END);
  long int size = ftell(file);
  fclose(file);
  // Reading data to array of unsigned chars
  file = fopen(binfilename, "r+");
  unsigned char * image = (unsigned char *) malloc(size);
  int bytes_read = fread(image, sizeof(unsigned char), size, file);
  fclose(file);

  /* init struct __tgt_device_image */
  struct __tgt_device_image * device_image = (struct __tgt_device_image *)
         malloc(sizeof(struct __tgt_device_image));
  device_image->ImageStart = image;
  device_image->ImageEnd = image + size;
  device_image->EntriesBegin = __start_omp_offloading_entries;
  device_image->EntriesEnd = __stop_omp_offloading_entries;


  struct __tgt_bin_desc * binDesc = (struct __tgt_bin_desc *)
          malloc(sizeof(struct __tgt_bin_desc));

  binDesc->NumDeviceImages = 1;
  binDesc->DeviceImages = device_image;
  binDesc->HostEntriesBegin = __start_omp_offloading_entries;
  binDesc->HostEntriesEnd = __stop_omp_offloading_entries;

  __tgt_register_lib(binDesc);
  return binDesc;
}

void axpy_ompacc(REAL* x, REAL* y, int n, REAL a) {
  int i;
/* //implementation of the following omp target region 
#pragma omp target teams distribute parallel for device (0) map(tofrom: y[0:n]) map(to: x[0:n],a,n) shared(x, y, n, a) private(i)
  for (i = 0; i < n; ++i)
    y[i] += a * x[i];
*/

  /* prepare the arguments for the __tgt_target runtime call 
  int __tgt_target(int64_t device_id, void *host_ptr, int32_t arg_num,
         void **args_base, void **args, int64_t *arg_sizes,
         int64_t *arg_types); 
		 
  int __tgt_target_teams(int64_t device_id, void *host_ptr, int32_t arg_num,
         void **args_base, void **args, int64_t *arg_sizes,
         int64_t *arg_types, int32_t num_teams,
         int32_t thread_limit); 
		 */

  //char axpy_cudakernel_binfilename[] = "a.out-axpy_cudakernel";
  char axpy_cudakernel_binfilename[] = "axpy_cudakernel.cubin";
  
  struct __tgt_bin_desc * binDesc = cubin2chararray_register(axpy_cudakernel_binfilename);

  int64_t device_id = 0;
  void * host_ptr = entry_ptr;
  int32_t arg_num = 4;
  void * args_base[] = {y, x, &n, &a};
  void * args[] = {y, x, &n, &a};
  //printf("y: %x, x: %x, n: %x, a: %x\n", y, x, &n, &a);
  /* size in bytes for each of the args in the same sequence order as in args */
  int64_t arg_sizes[] = {(int64_t)sizeof(REAL)*(n-0), (int64_t)sizeof(REAL)*(n-0), sizeof(int), sizeof(REAL)}; 
  /* map type for each of the args in the same sequence order as in args (y, x, n, a) */
  int64_t arg_types[] = {OMP_TGT_MAPTYPE_TARGET_PARAM | OMP_TGT_MAPTYPE_TO|OMP_TGT_MAPTYPE_FROM, OMP_TGT_MAPTYPE_TARGET_PARAM| OMP_TGT_MAPTYPE_TO, OMP_TGT_MAPTYPE_TARGET_PARAM| OMP_TGT_MAPTYPE_TO, OMP_TGT_MAPTYPE_TARGET_PARAM| OMP_TGT_MAPTYPE_TO};

  //if (0 == __tgt_target(device_id, host_ptr, arg_num, args_base, args, arg_sizes, arg_types)) {
  if (0 == __tgt_target_teams(device_id, host_ptr, arg_num, args_base, args, arg_sizes, arg_types, 1024, 256)) {
     /* successful offload */
     __tgt_unregister_lib(binDesc); //In clang/llvm, this is part of dctor inserted by the clang-offload-wrapper
     return;
  } else { /* execute it on host */
    printf("offloading failed, now run on CPU with OpenMP\n");
#pragma omp parallel for shared(x, y, n, a) private(i)
  for (i = 0; i < n; ++i)
    y[i] += a * x[i];
  }
}

int main(int argc, char *argv[])
{
  int n;
  REAL *y_ompacc, *y, *x;
  REAL a = 123.456;

  n = VEC_LEN;
  fprintf(stderr, "Usage: axpy <n>\n");
  if (argc >= 2) {
    n = atoi(argv[1]);
  }
  y_ompacc = (REAL *) malloc(n * sizeof(REAL));
  y  = (REAL *) malloc(n * sizeof(REAL));
  x = (REAL *) malloc(n * sizeof(REAL));

  srand48(1<<12);
  init(x, n);
  init(y_ompacc, n);
  memcpy(y, y_ompacc, n*sizeof(REAL));

  axpy(x, y, n, a);

  int i;
  int num_runs = 10;
  /* cuda version */
  double elapsed = read_timer_ms();
  for (i=0; i<num_runs; i++) axpy_ompacc(x, y, n, a);
  elapsed = (read_timer_ms() - elapsed)/num_runs;

  REAL checkresult = check(y_ompacc, y, n);
  printf("axpy(%d): checksum: %g, time: %0.2fms\n", n, checkresult, elapsed);
  //assert (checkresult < 1.0e-10);

  free(y_ompacc);
  free(y);
  free(x);
  return 0;
}
